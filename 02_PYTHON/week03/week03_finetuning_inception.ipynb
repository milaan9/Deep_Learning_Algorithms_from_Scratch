{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9cgWox0eiRB"
   },
   "source": [
    "# Fine-tuning InceptionV3 for flowers classification\n",
    "\n",
    "In this programming assignment you will fine-tune InceptionV3 architecture for flowers classification task.\n",
    "\n",
    "InceptionV3 architecture (https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html):\n",
    "<img src=\"images/inceptionv3.png\" style=\"width:70%\">\n",
    "\n",
    "Flowers classification dataset (http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) consists of 102 flower categories commonly occurring in the United Kingdom. Each class contains between 40 and 258 images:\n",
    "<img src=\"images/flowers.jpg\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "shred -u setup_colab.py\n",
    "\n",
    "wget https://raw.githubusercontent.com/hse-aml/intro-to-dl-pytorch/main/utils/setup_colab.py -O setup_colab.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup_colab\n",
    "\n",
    "setup_colab.setup_week03_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T15:26:09.068129Z",
     "start_time": "2021-02-14T15:26:08.219347Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1613301368013,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "yRsMV_1ReiRJ",
    "outputId": "6ac5089e-8352-4cdf-e0d9-4ecbc131e90e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import tqdm\n",
    "import collections\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T15:26:10.693869Z",
     "start_time": "2021-02-14T15:26:10.690502Z"
    },
    "executionInfo": {
     "elapsed": 1241,
     "status": "ok",
     "timestamp": 1613301369415,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "l_4fuEj3eiRL"
   },
   "outputs": [],
   "source": [
    "# auxiliary stuff\n",
    "def calculate_accuracy(prediction, target):\n",
    "    # Note that prediction.shape == target.shape == [B, ]\n",
    "    \n",
    "    matching = (prediction == target).float()\n",
    "    return matching.mean()\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10EpF5WxeiRM"
   },
   "source": [
    "# Fill in your Coursera token and email\n",
    "To successfully submit your answers to our grader, please fill in your Coursera submission token and email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 886,
     "status": "ok",
     "timestamp": 1613301369803,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "Pv_j04eUeiRM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import grading \n",
    "\n",
    "grader = grading.Grader(\n",
    "    assignment_key=\"2v-uxpD7EeeMxQ6FWsz5LA\", \n",
    "    all_parts=[\"wuwwC\", \"qRsZ1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1613301369804,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "j4Nvaj_HeiRM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = ### YOUR TOKEN HERE\n",
    "COURSERA_EMAIL = ### YOUR EMAIL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj0T4NEGeiRM"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bpvl_o4TeiRN"
   },
   "source": [
    "Dataset was downloaded for you, it takes 12 min and 400mb.\n",
    "Relevant links (just in case):\n",
    "- http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html\n",
    "- http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
    "- http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8012,
     "status": "ok",
     "timestamp": 1613301378451,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "WEl2X-PCeiRN",
    "outputId": "6d4e790b-dd54-4ba6-9a05-94d67d707b58",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import download_utils\n",
    "\n",
    "download_utils.download_week_3_resources('flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3692,
     "status": "ok",
     "timestamp": 1613301378670,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "yeqEDTbheiRN"
   },
   "outputs": [],
   "source": [
    "# unpack data into flowers/\n",
    "!tar -zxvf flowers/102flowers.tgz -C flowers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2968,
     "status": "ok",
     "timestamp": 1613301378671,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "9yn3HyAfeiRN"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# `datasets.ImageFolder` is a generic data loader\n",
    "# where the images are arranged in this way:\n",
    "#     root/dog/xxx.png\n",
    "#     root/dog/xxy.png\n",
    "#     root/dog/xxz.png\n",
    "#     ...\n",
    "#     root/cat/123.png\n",
    "#     root/cat/nsdf3.png\n",
    "#     root/cat/asd932_.png\n",
    "\n",
    "class FlowersDataset(datasets.ImageFolder):\n",
    "    \n",
    "    def __init__(self, path: str, transform = None):\n",
    "        super(FlowersDataset, self).__init__(path, transform=transform)\n",
    "        \n",
    "        # load labels from `*.mat` file\n",
    "        self.labels = loadmat(f'{path}/imagelabels.mat')['labels'][0] - 1\n",
    "        self.labels = self.labels.tolist()\n",
    "        self.classes = list(set(self.labels))\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        image, _ = super().__getitem__(index)\n",
    "        label = self.labels[index]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2325,
     "status": "ok",
     "timestamp": 1613301378672,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "U2_pK2xLeiRO"
   },
   "outputs": [],
   "source": [
    "dataset = FlowersDataset('flowers', transforms.PILToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1613301379463,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "It0ryjl8eiRO",
    "outputId": "02daecd6-12e6-41c5-a473-3d1fa6ef9277"
   },
   "outputs": [],
   "source": [
    "image, label = dataset[232]\n",
    "print(label)\n",
    "plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9qQphe5eiRO"
   },
   "source": [
    "## Prepare images for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myjLSMOIeiRO"
   },
   "source": [
    "We will take a center crop from each image like this:\n",
    "<img src=\"images/center_crop.jpg\" style=\"width:50%\">\n",
    "\n",
    "And then resize image to IMG_SIZE x IMG_SIZE, where IMG_SIZE = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1613301383275,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "Zk7V2tXbeiRO"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 299\n",
    "\n",
    "class CenterCrop2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CenterCrop2, self).__init__()\n",
    "    \n",
    "    def forward(self, image: torch.Tensor):\n",
    "        h, w = image.shape[-2:]\n",
    "        \n",
    "        s = h if w > h else w\n",
    "        image = ### YOUR CODE HERE ###\n",
    "        return image\n",
    "\n",
    "prepare_transforms = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    \n",
    "    # Convert from uint8 ([0, 255]) to float32 ([0.0, 0.1])\n",
    "    transforms.Lambda(lambda image: image.float() / 255.),\n",
    "    \n",
    "    # Center crop\n",
    "    CenterCrop2(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "\n",
    "    # Normalization\n",
    "    # This is necessary because the original model was trained\n",
    "    # with normalization and expects normalized input\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1613301387075,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "M-i7RvWBeiRP"
   },
   "outputs": [],
   "source": [
    "dataset = FlowersDataset('flowers', prepare_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "executionInfo": {
     "elapsed": 1402,
     "status": "ok",
     "timestamp": 1613301389754,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "R9fJyT3ueiRP",
    "outputId": "d1ab0684-5a03-4e95-9d40-8f94ae9f44df"
   },
   "outputs": [],
   "source": [
    "image, label = dataset[232]\n",
    "print(image.shape, label)\n",
    "plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image = torch.rand((3, 300, 250))\n",
    "cropped_image = CenterCrop2().forward(dummy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED PART, DO NOT CHANGE!\n",
    "grader.set_answer(\"qRsZ1\", cropped_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLRLnBZ6eiRP"
   },
   "source": [
    "## Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1613301392051,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "k2GT1v5NeiRP"
   },
   "outputs": [],
   "source": [
    "indexes = list(range(len(dataset)))\n",
    "train_indexes, test_indexes = train_test_split(\n",
    "    indexes,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=dataset.labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1613301393600,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "_0jAS8I1eiRP"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.Subset(dataset, train_indexes)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1613301395036,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "Do4dMgGPeiRP"
   },
   "outputs": [],
   "source": [
    "assert (len(train_dataset) + len(test_dataset)) == len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 689,
     "status": "ok",
     "timestamp": 1613301397282,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "x8OqtblDeiRQ"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# `pin_memory` speed up processing if you use GPU\n",
    "# `num_workers` also speed up processing since use additional process\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1613301407158,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "jC_evNB1eiRQ",
    "outputId": "2639ccc1-4224-4ebb-d4b8-2e28e7b5a322"
   },
   "outputs": [],
   "source": [
    "cols = 8\n",
    "rows = 2\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = random.randint(0, len(train_dataset) - 1)\n",
    "        \n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        image, label = train_dataset[random_index]\n",
    "        \n",
    "        # move the channel dimension to the end\n",
    "        images = image.permute(1, 2, 0)\n",
    "        \n",
    "        ax.imshow(images)\n",
    "        ax.set_title(label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33Wl-GgdeiRQ"
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qncR5sC1eiRQ"
   },
   "source": [
    "You cannot train such a huge architecture from scratch with such a small dataset.\n",
    "\n",
    "But using fine-tuning of last layers of pre-trained network you can get a pretty good classifier very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1613301409733,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "fW1C5QW2eiRR"
   },
   "outputs": [],
   "source": [
    "class PretrainedInceptionV3(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim: int):\n",
    "        super(PretrainedInceptionV3, self).__init__()\n",
    "        \n",
    "        # Download pretrained model and turn on eval regime\n",
    "        self.barebone = models.inception.inception_v3(\n",
    "            pretrained=True, progress=True, aux_logits=False\n",
    "        )\n",
    "        \n",
    "        # Freeze all layers\n",
    "        for p in self.barebone.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        \n",
    "        # Unfreeze penultimate block\n",
    "        # The network will adjust faster to new data\n",
    "        for p in self.barebone.Mixed_7c.parameters():\n",
    "            p.requires_grad_(True)\n",
    "        \n",
    "        # Replace the last Linear layer\n",
    "        in_features_final_fc = self.barebone.fc.in_features\n",
    "        self.barebone.fc = nn.Linear(in_features_final_fc, output_dim)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        return self.barebone(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSiurJXAeiRR"
   },
   "source": [
    "## Init train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 974,
     "status": "ok",
     "timestamp": 1613301441231,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "U8dzLTN_eiRR",
    "outputId": "87828ac2-8aaf-49c4-e792-00b07c1aaf8d"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 20\n",
    "DEVICE = torch.device('cuda:0')\n",
    "HISTORY = collections.defaultdict(list)\n",
    "\n",
    "model = PretrainedInceptionV3(output_dim=len(train_dataset.dataset.classes)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    lr=1e-2\n",
    ")\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "# This will speed up the convergence of the model\n",
    "lr_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer=optimizer,\n",
    "    milestones=[7, 15],\n",
    "    gamma=0.1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 25719,
     "status": "error",
     "timestamp": 1613302592535,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "xwdHAZpVeiRT",
    "outputId": "c6677906-e739-4939-962a-ab1f44b45f70"
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    # AverageMeter will accumulate average of some metric\n",
    "    train_loss_meter = AverageMeter()\n",
    "    train_accuracy_meter = AverageMeter()\n",
    "    test_loss_meter = AverageMeter()\n",
    "    test_accuracy_meter = AverageMeter()\n",
    "    \n",
    "    # training loop\n",
    "    # sets the module in training mode -- it i  s important for nn.Dropout\n",
    "    model.train()\n",
    "    # wrap `train_dataloader` within tqdm to visualize progress\n",
    "    for train_batch in tqdm.tqdm(train_dataloader):\n",
    "        \n",
    "        # unpack batch and move to specific device (for example, GPU or TPU)\n",
    "        images, labels = train_batch\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        # do forward pass\n",
    "        logits = model.forward(images)\n",
    "        prediction = logits.argmax(dim=-1)\n",
    "        \n",
    "        # calculate loss (CrossEntropy)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # zero out the previous gradients of our model parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate new gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # do optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate current average loss and accuracy\n",
    "        train_loss_meter.update(loss.item())\n",
    "        train_accuracy_meter.update(\n",
    "            calculate_accuracy(\n",
    "                prediction.detach(),\n",
    "                labels\n",
    "            ).item()\n",
    "        )\n",
    "    \n",
    "    # update lr_scheduler\n",
    "    lr_scheduler.step()\n",
    "        \n",
    "    # save average train loss and accuracy\n",
    "    HISTORY['train_loss'].append(train_loss_meter.avg)\n",
    "    HISTORY['train_accuracy'].append(train_accuracy_meter.avg)\n",
    "    \n",
    "    # lr_scheduler.get_last_lr() return list of LRs (one LR for each group)\n",
    "    HISTORY['learning_rate'].append(lr_scheduler.get_last_lr()[0])\n",
    "        \n",
    "    # testing loop\n",
    "    # sets the module in evaluation mode\n",
    "    model.eval()\n",
    "    for test_batch in test_dataloader:\n",
    "        images, labels = test_batch\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        # Ð°dd `with torch.no_grad()' to avoid computing gradients of weights\n",
    "        with torch.no_grad():\n",
    "            # do everything like we did in training loop\n",
    "            logits = model(images)\n",
    "            prediction = logits.argmax(dim=-1)\n",
    "            loss = criterion(logits, labels)\n",
    "        \n",
    "        test_loss_meter.update(loss.item())\n",
    "        test_accuracy_meter.update(\n",
    "            calculate_accuracy(\n",
    "                prediction,\n",
    "                labels\n",
    "            ).item()\n",
    "        )\n",
    "    \n",
    "    # save average test accuracy loss and accuracy\n",
    "    HISTORY['test_loss'].append(test_loss_meter.avg)\n",
    "    HISTORY['test_accuracy'].append(test_accuracy_meter.avg)\n",
    "    \n",
    "    # visualize all togather\n",
    "    display.clear_output()\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    \n",
    "    axes[0].set_title('Loss (Cross Entropy)')\n",
    "    axes[0].plot(HISTORY['train_loss'], label='Train Loss')\n",
    "    axes[0].plot(HISTORY['test_loss'], label='Test Loss')\n",
    "    axes[0].grid()\n",
    "    axes[0].legend(fontsize=20)\n",
    "    \n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].plot(HISTORY['train_accuracy'], label='Train Accuracy')\n",
    "    axes[1].plot(HISTORY['test_accuracy'], label='Test Accuracy')\n",
    "    axes[1].grid()\n",
    "    axes[1].legend(fontsize=20)\n",
    "    \n",
    "    axes[2].set_title('Learning Rate')\n",
    "    axes[2].plot(HISTORY['learning_rate'])\n",
    "    axes[2].grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1613302603840,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "hmvdQuxWvXhM"
   },
   "outputs": [],
   "source": [
    "assert max(HISTORY['test_accuracy']) > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1VGLh0veiRU"
   },
   "outputs": [],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "grader.set_answer(\"wuwwC\", max(HISTORY['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01ESdQ1-eiRV"
   },
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "week3_task2_fine_tuning_clean.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}