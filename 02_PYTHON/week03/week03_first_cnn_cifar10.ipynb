{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q474F0kK6rfr"
   },
   "source": [
    "# Your first CNN on CIFAR-10\n",
    "\n",
    "In this programming assignment you will: \n",
    "- define your first CNN architecture for CIFAR-10 dataset\n",
    "- train it from scratch\n",
    "- visualize learnt filters\n",
    "\n",
    "CIFAR-10 dataset contains 32x32 color images from 10 classes: __airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck__:\n",
    "\n",
    "<img src=\"images/cifar10.jpg\" style=\"width:80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "shred -u setup_colab.py\n",
    "\n",
    "wget https://raw.githubusercontent.com/hse-aml/intro-to-dl-pytorch/main/utils/setup_colab.py -O setup_colab.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup_colab\n",
    "\n",
    "setup_colab.setup_week03_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1252,
     "status": "ok",
     "timestamp": 1611560053136,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "L7K7HSco6rf3",
    "outputId": "52333b76-fc73-4c55-b746-51636a1afce2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import tqdm\n",
    "import itertools\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qTjDqUl6rf7"
   },
   "outputs": [],
   "source": [
    "#auxiliary stuff\n",
    "def calculate_accuracy(prediction, target):\n",
    "    # Note that prediction.shape == target.shape == [B, ]\n",
    "    \n",
    "    matching = (prediction == target).float()\n",
    "    return matching.mean()\n",
    "\n",
    "class AverageMeter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH-cgUV96rf8"
   },
   "source": [
    "### Fill in your Coursera token and email\n",
    "To successfully submit your answers to our grader, please fill in your Coursera submission token and email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIFFAOaY6rf9"
   },
   "outputs": [],
   "source": [
    "import grading\n",
    "\n",
    "grader = grading.Grader(\n",
    "    assignment_key=\"s1B1I5DuEeeyLAqI7dCYkg\",\n",
    "    all_parts=[\"7W4tu\", \"nQOsg\", \"96eco\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UJxeRa06rf9"
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = '### YOUR TOKEN HERE'\n",
    "COURSERA_EMAIL = '### YOUR EMAIL HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvPaOjsv6rf-"
   },
   "source": [
    "# CIFAR-10 dataset\n",
    "\n",
    "Set up datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2716,
     "status": "ok",
     "timestamp": 1611560054680,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "QsKV6zGY6rf_",
    "outputId": "d0836deb-d45e-47d5-cb84-b33d171b6b7c"
   },
   "outputs": [],
   "source": [
    "# Convert from PIL to torch.Tensort\n",
    "# and normalize each pixel from [0, 255] range to [0.0, 1.0]\n",
    "base_transforms = transforms.ToTensor()\n",
    "\n",
    "# An augmentation that randomly (with a probability equal to 0.5)\n",
    "# flips the image horizontally\n",
    "# This will prevent overfitting and make the model more robust\n",
    "aug_transforms = transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "# Gather all transforms together\n",
    "train_transforms = transforms.Compose([\n",
    "    base_transforms,\n",
    "    aug_transforms\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10('./', train=True, download=True, transform=train_transforms)\n",
    "\n",
    "# Note that we only use `base_transforms` for test dataset\n",
    "test_dataset = datasets.CIFAR10('./', train=False, download=True, transform=base_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kq6XU786rgA"
   },
   "source": [
    "Let's look at a batch of random train images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 4111,
     "status": "ok",
     "timestamp": 1611560056109,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "P5sORod36rgA",
    "outputId": "6e495cec-99f5-425a-c89d-100bd20f5e65"
   },
   "outputs": [],
   "source": [
    "index2class = {v: k for k, v in train_dataset.class_to_idx.items()}\n",
    "\n",
    "cols = 8\n",
    "rows = 2\n",
    "\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = random.randint(0, len(train_dataset) - 1)\n",
    "        \n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        image, label = train_dataset[random_index]\n",
    "        \n",
    "        # move the channel dimension to the end\n",
    "        images = image.permute(1, 2, 0)\n",
    "        \n",
    "        ax.imshow(images)\n",
    "        ax.set_title(index2class[label])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-29cClXw6rgC"
   },
   "source": [
    "As usual, let's wrap our datasets in data dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMfowoCW6rgC"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# `pin_memory` speed up processing if you use GPU\n",
    "# `num_workers` also speed up processing since use additional process\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=0, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVS6YFDp6rgC"
   },
   "source": [
    "# CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ux3QwLXR6rgD"
   },
   "source": [
    "Convolutional networks are built from several types of layers:\n",
    "- [Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) - performs convolution:\n",
    "- [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) - performs 2D max pooling.\n",
    "- [Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) - flattens the input, does not affect the batch size.\n",
    "- [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) - fully-connected layer.\n",
    "- [LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html) - applies leaky relu activation.\n",
    "- [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) - applies dropout.\n",
    "\n",
    "Feel free to learn official documentation about other basic building blocks: https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39WzwFt96rgD"
   },
   "source": [
    "You need to define a model which takes __(None, 32, 32, 3)__ input and predicts __(None, 10)__ output with probabilities for all classes. __None__ in shapes stands for batch dimension.\n",
    "\n",
    "Simple feed-forward networks in PyTorch can be defined in the following way:\n",
    "\n",
    "```python\n",
    "model = nn.Sequential()  # start feed-forward model definition\n",
    "model.add_module('block_name', nn.Conv2d(in_channels=..., out_channels=..., kernel_size=...))\n",
    "\n",
    "...  # here comes a bunch of convolutional, pooling and dropout layers\n",
    "\n",
    "model.add_module('block_name', nn.Linear(in_features=..., out_features=...))  # the last layer with a neuron for each class\n",
    "```\n",
    "\n",
    "Or you can immediately define layers within `nn.Sequential`:\n",
    "\n",
    "```python\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=..., out_channels=..., kernel_size=...),\n",
    "    nn.LeakyReLU(...),\n",
    "    # and so on\n",
    ")\n",
    "```\n",
    "\n",
    "### Architecture details\n",
    "Stack __4__ convolutional layers with kernel size __(3, 3)__ with growing number of filters __(16, 32, 32, 64)__.\n",
    "Don't forget to add `padding` argument to each convolutional layers so that the shape of the image is not reduced.\n",
    "Try to figure out what size padding is needed for each dimension (height and width).\n",
    "\n",
    "Add __2x2__ pooling layer after every 2 convolutional layers (conv-conv-pool scheme).\n",
    "\n",
    "Use __LeakyReLU__ activation with recommended parameter __0.1__ for all layers that need it (after convolutional and linear layers):\n",
    "```python\n",
    "model.append(nn.LeakyReLU(0.1))\n",
    "```\n",
    "\n",
    "Add a __Linear__ layer with __256__ output neurons and a second __Linear__ layer with __10__ neurons for classes.\n",
    "Remember to use __Flatten__ layer before first dense layer to reshape input volume into a flat vector!\n",
    "\n",
    "Add __Dropout__ after every pooling layer (__0.25__) and between __Linear__ layers (__0.5__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvZJOw8v6rgE"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        # define layers\n",
    "\n",
    "        ### YOUR CODE HERE ###\n",
    "    )\n",
    "    \n",
    "    # Don't add Softmax or something else to the end!\n",
    "    # We will use nn.CrossEntropyLoss which does this itself.\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8s9P6me6rgE"
   },
   "outputs": [],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYb2CHx-6rgF"
   },
   "outputs": [],
   "source": [
    "def get_num_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhXTvK9W6rgF"
   },
   "outputs": [],
   "source": [
    "assert get_num_parameters(model) > 1_000_000, 'Oops, make sure you did everything according to instruction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auWOYiyF6rgG"
   },
   "outputs": [],
   "source": [
    "# GRADED PART, DO NOT CHANGE!\n",
    "grader.set_answer(\"7W4tu\", get_num_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vpqe2brF6rgG"
   },
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUlzOziq6rgG"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "During training you should observe the decrease in reported loss on training and test. If the loss on training is not decreasing with epochs you should revise your model definition and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7555,
     "status": "ok",
     "timestamp": 1611560059679,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "vI1482qv6rgH",
    "outputId": "eab4e9a6-529c-4f29-cf2e-7a81f8c8ff5e"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 50\n",
    "DEVICE = torch.device('cuda:0')\n",
    "HISTORY = collections.defaultdict(list)\n",
    "\n",
    "model = make_model().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "# This will speed up the convergence of the model\n",
    "lr_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer=optimizer,\n",
    "    milestones=[20, 40],\n",
    "    gamma=0.1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 985375,
     "status": "ok",
     "timestamp": 1611561037527,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "NJY_jfd66rgI",
    "outputId": "707291b0-a476-4eb7-f66a-4e5645bf8f7f"
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCH):\n",
    "    # AverageMeter will accumulate average of some metric\n",
    "    train_loss_meter = AverageMeter()\n",
    "    train_accuracy_meter = AverageMeter()\n",
    "    test_loss_meter = AverageMeter()\n",
    "    test_accuracy_meter = AverageMeter()\n",
    "    \n",
    "    # training loop\n",
    "    # sets the module in training mode -- it is important for nn.Dropout\n",
    "    model.train()\n",
    "    # wrap `train_dataloader` within tqdm to visualize progress\n",
    "    for train_batch in tqdm.tqdm(train_dataloader):\n",
    "        \n",
    "        # unpack batch and move to specific device (for example, GPU or TPU)\n",
    "        images, labels = train_batch\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        # do forward pass\n",
    "        logits = model(images)\n",
    "        prediction = logits.argmax(dim=-1)\n",
    "        \n",
    "        # calculate loss (CrossEntropy)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # zero out the previous gradients of our model parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate new gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # do optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate current average loss and accuracy\n",
    "        train_loss_meter.update(loss.item())\n",
    "        train_accuracy_meter.update(\n",
    "            calculate_accuracy(\n",
    "                prediction.detach(),\n",
    "                labels\n",
    "            ).item()\n",
    "        )\n",
    "    \n",
    "    # update lr_scheduler\n",
    "    lr_scheduler.step()\n",
    "        \n",
    "    # save average train loss and accuracy\n",
    "    HISTORY['train_loss'].append(train_loss_meter.avg)\n",
    "    HISTORY['train_accuracy'].append(train_accuracy_meter.avg)\n",
    "    \n",
    "    # lr_scheduler.get_last_lr() return list of LRs (one LR for each group)\n",
    "    HISTORY['learning_rate'].append(lr_scheduler.get_last_lr()[0])\n",
    "        \n",
    "    # testing loop\n",
    "    # sets the module in evaluation mode\n",
    "    model.eval()\n",
    "    for test_batch in test_dataloader:\n",
    "        images, labels = test_batch\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        # Ð°dd `with torch.no_grad()' to avoid computing gradients of weights\n",
    "        with torch.no_grad():\n",
    "            # do everything like we did in training loop\n",
    "            logits = model(images)\n",
    "            prediction = logits.argmax(dim=-1)\n",
    "            loss = criterion(logits, labels)\n",
    "        \n",
    "        test_loss_meter.update(loss.item())\n",
    "        test_accuracy_meter.update(\n",
    "            calculate_accuracy(\n",
    "                prediction,\n",
    "                labels\n",
    "            ).item()\n",
    "        )\n",
    "    \n",
    "    # save average test accuracy loss and accuracy\n",
    "    HISTORY['test_loss'].append(test_loss_meter.avg)\n",
    "    HISTORY['test_accuracy'].append(test_accuracy_meter.avg)\n",
    "    \n",
    "    # visualize all togather\n",
    "    display.clear_output()\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "    \n",
    "    axes[0].set_title('Loss (Cross Entropy)')\n",
    "    axes[0].plot(HISTORY['train_loss'], label='Train Loss')\n",
    "    axes[0].plot(HISTORY['test_loss'], label='Test Loss')\n",
    "    axes[0].grid()\n",
    "    axes[0].legend(fontsize=20)\n",
    "    \n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].plot(HISTORY['train_accuracy'], label='Train Accuracy')\n",
    "    axes[1].plot(HISTORY['test_accuracy'], label='Test Accuracy')\n",
    "    axes[1].grid()\n",
    "    axes[1].legend(fontsize=20)\n",
    "    \n",
    "    axes[2].set_title('Learning Rate')\n",
    "    axes[2].plot(HISTORY['learning_rate'])\n",
    "    axes[2].grid()\n",
    "    \n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yloBA5SX6rgK"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1611561268803,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "OgwJ34zFZHSW",
    "outputId": "0c8afbb4-e428-42e6-cd85-b5ffed477ce8"
   },
   "outputs": [],
   "source": [
    "weights = torch.load('model_weights.pt', map_location=DEVICE)\n",
    "model = make_model().to(DEVICE)\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsbUMFrP6rgL"
   },
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vd7U0WKxZHSW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUzeahbdZHSW"
   },
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "predictions = []\n",
    "\n",
    "model.eval()\n",
    "for test_batch in test_dataloader:\n",
    "    images, labels = test_batch\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(images)\n",
    "        prediction = logits.argmax(dim=-1).cpu()\n",
    "    \n",
    "    ground_truth.append(labels.cpu())\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# concatenate tensors into one\n",
    "ground_truth = torch.cat(ground_truth).numpy()\n",
    "predictions = torch.cat(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1611561280672,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "uRFnxufSZHSX",
    "outputId": "d5e0bd65-79c1-4cdb-8c37-dd84624ea8bf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.imshow(\n",
    "    confusion_matrix(\n",
    "        ground_truth,\n",
    "        predictions\n",
    "    )\n",
    ")\n",
    "plt.xticks(np.arange(10), train_dataset.classes, rotation=45, fontsize=12)\n",
    "plt.yticks(np.arange(10), train_dataset.classes, fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bk-phwuQMbkv"
   },
   "outputs": [],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "# Accuracy on validation data\n",
    "grader.set_answer(\"nQOsg\", accuracy_score(ground_truth, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MstAtaMCMfGO"
   },
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "executionInfo": {
     "elapsed": 1371,
     "status": "ok",
     "timestamp": 1611561282950,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "2pxLdA-Q6rgM",
    "outputId": "bb818168-f241-4c7f-ed15-82c2ef9afb99"
   },
   "outputs": [],
   "source": [
    "# inspect preditions\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        \n",
    "        random_index = random.randint(0, len(test_dataset) - 1)\n",
    "        \n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        image, label = test_dataset[random_index]\n",
    "        \n",
    "        # move the channel dimension to the end\n",
    "        images = image.permute(1, 2, 0)\n",
    "        \n",
    "        ax.imshow(images)\n",
    "        ax.set_title(f\"Prediction: {index2class[predictions[random_index].item()]}\\n\"\n",
    "                     f\"True Label: {index2class[label]}\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvaQt2AM6rgM"
   },
   "source": [
    "# Visualize maximum stimuli\n",
    "\n",
    "https://arxiv.org/pdf/1506.06579.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6WaJ73q6rgM"
   },
   "source": [
    "We want to find input images that provide maximum activations for particular layers of our network. \n",
    "\n",
    "We will find those maximum stimuli via gradient ascent in image space.\n",
    "\n",
    "For that task we load our model weights, calculate the layer output gradient with respect to image input and shift input image in that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcP211JZZHSX"
   },
   "outputs": [],
   "source": [
    "def freeze_weights(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad_(False)\n",
    "\n",
    "def image2rgb(image):\n",
    "    # normalize image so that mean is 0 and std 0.25\n",
    "    # don't forget to add eps(1e-7) to denominator\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # do reverse normalization to RGB values: x = (x_norm + 0.5) * 255\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # clip values to [0, 255] and convert to bytes\n",
    "    x = torch.clamp(x, 0, 255) \\\n",
    "        .squeeze(0) \\\n",
    "        .permute(1, 2, 0) \\\n",
    "        .byte()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def find_maximum_stimuli(\n",
    "    model: nn.Module,\n",
    "    layer_index: int,\n",
    "    filter_index: int,\n",
    "    step_size: float = 0.1,\n",
    "    input_size: list = (32, 32),\n",
    "    iterations: int = 1,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    layer = model[layer_index]\n",
    "    \n",
    "    if get_num_parameters(layer) == 0:\n",
    "        raise ValueError(f\"{layer} don't have trainable parameters!\")\n",
    "    \n",
    "    is_conv = True if isinstance(layer, nn.Conv2d) else False\n",
    "    \n",
    "    new_model = model[:layer_index + 1]\n",
    "    freeze_weights(new_model)\n",
    "    \n",
    "    # sampled from Uniform[0, 1]\n",
    "    image = torch.rand(1, 3, *input_size).to(DEVICE)\n",
    "    image = (image - 0.5) * (0.1 if is_conv else 0.001)\n",
    "    \n",
    "    # ensure gradient will be computed\n",
    "    image.requires_grad_(True)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        feature_map = new_model(image)\n",
    "        \n",
    "        if is_conv:\n",
    "            loss = feature_map[:, filter_index].mean()\n",
    "        else:\n",
    "            loss = feature_map[:, filter_index].mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        grad = image.grad\n",
    "        # change only the values of tensor (not variable)\n",
    "        image.data += step_size * (grad / (torch.norm(grad) + 1e-10))\n",
    "        grad.data.zero_()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Current loss: {loss}')\n",
    "            \n",
    "    return image2rgb(image.detach()).cpu(), loss.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBfV4MMZ6rgO"
   },
   "outputs": [],
   "source": [
    "def plot_filters_stimuli(\n",
    "    model: nn.Module,\n",
    "    layer_index: int,\n",
    "    iterations=20,\n",
    "    step_size=1.,\n",
    "    verbose=False\n",
    "):\n",
    "    cols = 8\n",
    "    rows = 2\n",
    "    filter_index = 0\n",
    "    \n",
    "    # expecting that `model[layer_index]` is nn.Conv or nn.Linear\n",
    "    max_filter_index = model[layer_index].weight.shape[0] - 1\n",
    "    \n",
    "    fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1), dpi=100)\n",
    "    \n",
    "    for i in range(cols):\n",
    "        for j in range(rows):\n",
    "            \n",
    "            if filter_index <= max_filter_index:\n",
    "                ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "                ax.grid('off')\n",
    "                ax.axis('off')\n",
    "                loss = -1e20\n",
    "                \n",
    "                while loss < 0 and filter_index <= max_filter_index:\n",
    "                    stimuli, loss = find_maximum_stimuli(\n",
    "                        model=model,\n",
    "                        layer_index=layer_index,\n",
    "                        filter_index=filter_index,\n",
    "                        step_size=step_size,\n",
    "                        iterations=iterations,\n",
    "                        verbose=verbose\n",
    "                    )\n",
    "                    \n",
    "                    filter_index += 1\n",
    "\n",
    "                if loss > 0:\n",
    "                    ax.imshow(stimuli)\n",
    "                    ax.set_title(\"Filter #{}\".format(filter_index))\n",
    "                \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rx4wbXk6ZHSY"
   },
   "source": [
    "# Maximum stimuli for convolutional neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4380,
     "status": "ok",
     "timestamp": 1611561324634,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "B7UOxM1JZHSY",
    "outputId": "046112eb-4c01-4ca1-c059-d349bece188e"
   },
   "outputs": [],
   "source": [
    "for index_layer, layer in enumerate(model.children()):\n",
    "    if isinstance(layer, nn.Conv2d): \n",
    "        print(\n",
    "            f'Layer: {layer}\\n'\n",
    "            f'Index Layer: {index_layer}'\n",
    "        )\n",
    "        \n",
    "        # play with the number of iterations and the `step_size\n",
    "        # this can give you several different filters\n",
    "        plot_filters_stimuli(model, index_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIqff2mWZHSY"
   },
   "source": [
    "# Maximum stimuli for last linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1611561471456,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "AASMAAajjGpJ",
    "outputId": "685c1934-74ef-4ac4-e144-f25fcff2f21d"
   },
   "outputs": [],
   "source": [
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "executionInfo": {
     "elapsed": 4448,
     "status": "ok",
     "timestamp": 1611561330352,
     "user": {
      "displayName": "Alexander Markovich",
      "photoUrl": "",
      "userId": "05353592946685554048"
     },
     "user_tz": -180
    },
    "id": "Zjzra387ZHSY",
    "outputId": "08bd9910-e687-436b-921a-a63a470d9a58"
   },
   "outputs": [],
   "source": [
    "plot_filters_stimuli(\n",
    "    model,\n",
    "    # index of last linear layer\n",
    "    layer_index=16,\n",
    "    iterations=200,\n",
    "    step_size=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_stimuli_test_for_grader():\n",
    "    stimuli, loss = find_maximum_stimuli(\n",
    "        model,\n",
    "        layer_index=16,\n",
    "        filter_index=9,\n",
    "        verbose=False\n",
    "    )\n",
    "    return round(stimuli.float().mean().item()), round(stimuli.float().std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgbVEVLs6rgQ"
   },
   "outputs": [],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "# Maximum stimuli test\n",
    "grader.set_answer(\"96eco\", maximum_stimuli_test_for_grader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pb0W7QVT6rgQ"
   },
   "outputs": [],
   "source": [
    "# you can make submission with answers so far to check yourself at this stage\n",
    "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgNnTu5B6rgQ"
   },
   "source": [
    "# That's it! Congratulations!\n",
    "\n",
    "What you've done:\n",
    "- defined CNN architecture\n",
    "- trained your model\n",
    "- evaluated your model\n",
    "- visualised learnt filters"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "week3_task1_first_cnn_cifar10_clean.ipynb",
   "provenance": [
    {
     "file_id": "1g-_j8EDuWp8qexYiheJBBaX3jp82YOG_",
     "timestamp": 1611561536397
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}